episode_reward_max,episode_reward_min,episode_reward_mean,episode_len_mean,episodes_this_iter,num_healthy_workers,timesteps_total,timesteps_this_iter,agent_timesteps_total,done,episodes_total,training_iteration,trial_id,experiment_id,date,timestamp,time_this_iter_s,time_total_s,pid,hostname,node_ip,time_since_restore,timesteps_since_restore,iterations_since_restore,hist_stats/episode_reward,hist_stats/episode_lengths,timers/sample_time_ms,timers/sample_throughput,timers/load_time_ms,timers/load_throughput,timers/learn_time_ms,timers/learn_throughput,timers/update_time_ms,info/num_steps_sampled,info/num_agent_steps_sampled,info/num_steps_trained,info/num_agent_steps_trained,perf/cpu_util_percent,perf/ram_util_percent,perf/gpu_util_percent0,perf/vram_util_percent0,info/learner/default_policy/learner_stats/allreduce_latency,info/learner/default_policy/learner_stats/cur_kl_coeff,info/learner/default_policy/learner_stats/cur_lr,info/learner/default_policy/learner_stats/total_loss,info/learner/default_policy/learner_stats/policy_loss,info/learner/default_policy/learner_stats/vf_loss,info/learner/default_policy/learner_stats/vf_explained_var,info/learner/default_policy/learner_stats/kl,info/learner/default_policy/learner_stats/entropy,info/learner/default_policy/learner_stats/entropy_coeff
nan,nan,nan,nan,0,5,20000,0,20000,False,0,1,a1ff2_00000,42c5c0d5192b4285a12cfe46ef9476e3,2023-12-16_19-47-29,1702734449,9.198995113372803,9.198995113372803,49016,HPC005,10.33.1.26,9.198995113372803,0,1,[],[],8177.624,2445.698,0.566,35320454.737,1028.271,19450.126,7.488,20000,20000,20000,20000,29.923076923076923,52.93076923076922,0.03076923076923077,0.017953725961538464,0.0,0.2,0.0005,109.12805557250977,-0.00047969912215961585,109.15044403076172,-1.6808509826660156e-05,0.00029496288534481153,2.196894884109497,0.01
